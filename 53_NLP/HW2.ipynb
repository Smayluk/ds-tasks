{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import bz2\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201030it [01:30, 2215.92it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Домашнее задание по NLP # 2 [100 баллов] \n",
    "## Составление словарей для классификации по тональности\n",
    "При классификации текстов или предложений по тональности необходимо использовать оценочные словари для предметной области, то есть, такие словари, в которых содержатся отрицательные и позитивные слова для какой-то предметной области. Идея подобных словарей основана на следующих наблюдениях: во-первых, для разных товаров используются разные оценочные слова (например бывает “захватывающая книга”, но не бывает “захватывающих лыж”), во-вторых, в контексте разных товаров одни и те же слова могут иметь разную окраску (слово “тормоз” в отзыве на велосипед имеет нейтральную окраску, в отзыве на компьютер – резко негативную, “пыль” в контексте пылесосов – нейтральную, в контексте кофемолок – положительную (“мелкий помол в пыль”)). Еще один пример: \"теплое пиво\" – это плохо, а \"теплый свитер\" – это хорошо.  \n",
    "\n",
    "Составление таких словарей в ручную – трудоемкий процесс, но, к счастью, его не сложно автоматизировать, если собрать достаточно большие корпуса отзывов. В этом домашнем задании вам предстоит попробовать реализовать один их подходов к составлению оценочных словарей, основанный на статье Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora (https://nlp.stanford.edu/pubs/hamilton2016inducing.pdf).\n",
    "\n",
    "\n",
    "Данные для задания – уже знакомые вам отзывы на банки, собранные с нескольких сайтов Рунета. Отзывы могут быть как положительными (оценка 5), так и отрицательными (оценка 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'ronnichka',\n",
       " 'bank_license': 'лицензия № 880',\n",
       " 'bank_name': 'Югра',\n",
       " 'city': 'г. Саратов',\n",
       " 'datetime': '2015-06-03 20:56:57',\n",
       " 'num_comments': 0,\n",
       " 'rating_grade': 3,\n",
       " 'rating_not_checked': False,\n",
       " 'text': 'Здравствуйте! Хотела написать, что мне месяц не выдают карту ко вкладу, ссылаясь на \"нам же их из Самары везут\" (на секундочку 5 часов езды от нашего города). Но! Прочитала, что людям 3,5 месяцев не выдают карту, и поняла, что у меня все хорошо, пока что. И подарок мне дали, и кулер в отделении есть. Так что я, конечно, готова ждать. Правда хотелось бы не очень долго.',\n",
       " 'title': 'Карта ко вкладу'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Обучение модели word2vec [50 баллов]\n",
    "\n",
    "1. Разбейте всю коллекцию отзывов на предложения. Лемматизируйте все слова. \n",
    "2. Обучите по коллекции предложений word2vec\n",
    "3. Приведите несколько удачных и неудачных примеров решения стандартных текстов для word2vec:\n",
    "    * тест на определение ближайших слов\n",
    "    * тест на аналогии (мужчина – король : женщина – королева)\n",
    "    * тест на определение лишнего слова.\n",
    "    \n",
    "4. Постройте несколько визуализаций:\n",
    "    * TSNE для топ-100 (или топ-500) слов и найдите осмысленные кластеры слов\n",
    "    * задайте координаты для нового пространства следующим образом: одна  ось описывает отношение \"плохо – хорошо\", вторая – \"медленно – быстро\" и найдите координаты названий банков в этих координатах.  Более формально:\n",
    "    берем вектор слова \"хорошо\", вычитаем из него вектор слова \"плохо\", получаем новый вектор, который описывает разницу между хорошими и плохими словами. Берем вектор слова \"сбербанк\" и умножаем его на этот новый вектор – получаем координату по первой оси. Аналогично – для второй оси. Две координаты уже можно нарисовать на плоскости.  \n",
    " \n",
    "\n",
    "\n",
    "Ссылка на примеры визуализаций: https://towardsdatascience.com/game-of-thrones-word-embeddings-does-r-l-j-part-2-30290b1c0b4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Разбейте всю коллекцию отзывов на предложения. Лемматизируйте все слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, world!', 'How are you?', 'i am fine']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = 'Hello, world! How are you? i am fine'\n",
    "# sents = sent_tokenize(text)\n",
    "# sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "\n",
    "regex = re.compile(\"[А-Яа-я:=!\\)\\()A-z\\_\\%/|]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"banki_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.iloc[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разбиваем на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(df)):\n",
    "    sentences.extend(sent_tokenize(df.text.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лемматезируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [lemmatize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "готовим слова к Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [sentence.split() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучите по коллекции предложений word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(texts, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Приведите несколько удачных и неудачных примеров решения стандартных текстов для word2vec:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     * тест на определение ближайших слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('на', 0.17958682775497437),\n",
       " ('по', 0.17549686133861542),\n",
       " ('еще', 0.1002361997961998),\n",
       " ('карта', 0.09691773355007172),\n",
       " ('с', 0.09683242440223694),\n",
       " ('что', 0.022728752344846725),\n",
       " ('сумма', 0.013222230598330498),\n",
       " ('за', -0.002142559736967087),\n",
       " ('который', -0.006461970508098602),\n",
       " ('от', -0.008563635870814323)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"счет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    * тест на аналогии (мужчина – король : женщина – королева)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('на', 0.23098741471767426),\n",
       " ('карта', 0.19126522541046143),\n",
       " ('еще', 0.14981615543365479),\n",
       " ('за', 0.09502191841602325),\n",
       " ('который', 0.09262774884700775),\n",
       " ('в', 0.06778114289045334),\n",
       " ('быть', 0.058735739439725876),\n",
       " ('что', 0.0477982833981514),\n",
       " ('денежный', 0.047013282775878906),\n",
       " ('сумма', 0.03461284562945366)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"счет\",\"мой\"], negative=[\"менеджер\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    * тест на определение лишнего слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'карта'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"еще счет карта\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Распространение метки [50 баллов]\n",
    "\n",
    "Определите 5-8 позитивных слов (например, “быстрый”, “удобный”) и 5-8  негативных слов (например,“очередь”, “медленно”). Эти слова будут основной будущего оценочного словаря. Пусть позитивному классу соответствует метка 1, негативному – -1. Пометьте выбранные слова в лексическом графе соответствующими метками. Запустите любой известный вам метод распространения метки (Label Propogation) в лексическом графе. На выходе метода распространения ошибки должны быть новые слова, помеченные метками 1 и -1 – это и есть искомые оценочные слова.\n",
    "\n",
    "Алгоритмы распространения метки устроены примерно так: пусть мы находимся в выршине, помеченном +1. С какой-то вероятностью мы переносим эту метку на соседние узлы. С меньшей вероятностью переносим ее на вершины на расстоянии два. В конце распространения метки, часть вершин оказывается помечена меткой +1, часть – -1, большая часть остается без метки.\n",
    "\n",
    "Рекомендуемые алгоритмы распространения метки:\n",
    "1. ```graphlab.label_propagation``` (```graphlab``` доступен бесплатно по образовательной лицензии)\n",
    "2. ```sklearn.semi_supervised.LabelPropagation``` \n",
    "3. ```sklearn.semi_supervised.LabelSpreading```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'igraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9e615dea0da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# пример построения графа\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0migraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'igraph'"
     ]
    }
   ],
   "source": [
    "# пример построения графа \n",
    "\n",
    "import igraph as ig\n",
    "g = ig.Graph(directed=True)\n",
    "for word in model.wv.vocab.keys():\n",
    "    g.add_vertex(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "for word in model.wv.vocab.keys() :\n",
    "    node = g.vs.select(name = word).indices[0]\n",
    "    similar_words = model.most_similar(word, topn=5)\n",
    "    for sim in similar_words:\n",
    "        word1 = sim[0]\n",
    "        val  = sim[1]\n",
    "        new_node = g.vs.select(name = word1).indices[0]\n",
    "        g.add_edge(node, new_node, weight = val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
