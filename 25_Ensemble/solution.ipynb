{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАНЯТИЕ 2.5. АНСАМБЛИ МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#устраним ошибки со шрифтами\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Бэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание задачи\n",
    "\n",
    "Используем данные страхового подразделения BNP Paribas из соревнования\n",
    "\n",
    "https://www.kaggle.com/c/bnp-paribas-cardif-claims-management\n",
    "\n",
    "Решается задача классификации страховых случаев:\n",
    "    1. Случаи, требующие дополнительных документов для подтвердения (0)\n",
    "    2. Случаи, которые можно подтверждать автоматически на основе имеющейся информации (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим размер данных для ускорения обучения, возмем случайную подвыборку 20% данных со стратификацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# random_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=777)\n",
    "\n",
    "# for train_index, test_index in random_splitter.split(data, data.target):\n",
    "#     data = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучение и hold-out тест 70/30. Данных достаточно много, поэтому можно принебречь честной кросс-валидацией и оценивать модель на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.3, random_state=777)\n",
    "\n",
    "for train_index, test_index in splitter.split(data, data.SalePrice):\n",
    "    d_train = data.iloc[train_index]\n",
    "    d_test = data.iloc[test_index]\n",
    "    \n",
    "    y_train = data['SalePrice'].iloc[train_index]\n",
    "    y_test = data['SalePrice'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение значений таргета (event rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.SalePrice.value_counts()/ len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим категориальные признаки\n",
    "\n",
    "Чтобы в разы не увеличивать число признаков при построении dummy, будем использовать категориальные признаки с < 30 уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning          5\n",
      "Street            2\n",
      "Alley             2\n",
      "LotShape          4\n",
      "LandContour       4\n",
      "Utilities         1\n",
      "LotConfig         5\n",
      "LandSlope         3\n",
      "Neighborhood     25\n",
      "Condition1        9\n",
      "Condition2        8\n",
      "BldgType          5\n",
      "HouseStyle        8\n",
      "RoofStyle         6\n",
      "RoofMatl          7\n",
      "Exterior1st      15\n",
      "Exterior2nd      16\n",
      "MasVnrType        4\n",
      "ExterQual         4\n",
      "ExterCond         5\n",
      "Foundation        6\n",
      "BsmtQual          4\n",
      "BsmtCond          4\n",
      "BsmtExposure      4\n",
      "BsmtFinType1      6\n",
      "BsmtFinType2      6\n",
      "Heating           6\n",
      "HeatingQC         4\n",
      "CentralAir        2\n",
      "Electrical        5\n",
      "KitchenQual       4\n",
      "Functional        6\n",
      "FireplaceQu       5\n",
      "GarageType        6\n",
      "GarageFinish      3\n",
      "GarageQual        5\n",
      "GarageCond        5\n",
      "PavedDrive        3\n",
      "PoolQC            3\n",
      "Fence             4\n",
      "MiscFeature       4\n",
      "SaleType          9\n",
      "SaleCondition     6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_feat = list(data.dtypes[data.dtypes == object].index)\n",
    "\n",
    "#закодируем пропущенные значений строкой, факт пропущенного значения тоже может нести в себе информацию\n",
    "data[cat_feat] = data[cat_feat].fillna('nan')\n",
    "\n",
    "#отфильтруем непрерывные признаки\n",
    "num_feat = [f for f in data if f not in (cat_feat + ['ID', 'SalePrice'])]\n",
    "\n",
    "cat_nunique = d_train[cat_feat].nunique()\n",
    "print(cat_nunique)\n",
    "cat_feat = list(cat_nunique[cat_nunique < 30].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Композиции моделей одного семейства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будем использовать решающие деревья\n",
    "\n",
    "1. Неустойчивы к входным данным\n",
    "2. Склонны к переобучению\n",
    "3. Быстро обучаются\n",
    "\n",
    "=> отличный выбор для построения композиций\n",
    "\n",
    "**Создаем признаки для \"деревянных\" моделей**\n",
    "\n",
    "1. Заменяем пропуски на специальное значение -999, чтобы деревья могли их отличить\n",
    "3. Создаем дамми-переменные для категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train = pd.get_dummies(d_train[cat_feat], columns=cat_feat)\n",
    "dummy_test = pd.get_dummies(d_test[cat_feat], columns=cat_feat)\n",
    "\n",
    "dummy_cols = list(set(dummy_train) & set(dummy_test))\n",
    "\n",
    "dummy_train = dummy_train[dummy_cols]\n",
    "dummy_test = dummy_test[dummy_cols]\n",
    "\n",
    "\n",
    "X_train = pd.concat([d_train[num_feat].fillna(-999),\n",
    "                     dummy_train], axis=1)\n",
    "\n",
    "X_test = pd.concat([d_test[num_feat].fillna(-999),\n",
    "                     dummy_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем решающее дерево\n",
    "\n",
    "Немного ограничим глубину и минимальное кол-во объектов в листе для уменьшения переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=15, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=20,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf_tree = DecisionTreeRegressor(max_depth=15, min_samples_leaf=20)\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for DecisionTreeRegressor: 945434594.60\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error for DecisionTreeRegressor: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1236487028.51\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, regr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Бэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем готовый алгоритм из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=15, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=20,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=20, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bag_clf = BaggingRegressor(n_estimators=20, base_estimator=clf_tree, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340557788199475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8694370970297677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Случайный лес\n",
    "\n",
    "Бэггинг + случайные подпространства = случайный лес\n",
    "\n",
    "**Важные гиперпараметры алгоритма**\n",
    "\n",
    "a. Параметры деревьев\n",
    "    1. criterion - критерий построения дерева\n",
    "    2. max_depth - максимальная глубина дерева (обычно 10-20, больше глубина -> больше риск переобучения)\n",
    "    3. min_samples_leaf - минимальное число объектов в листе (обычно 20+, больше объектов -> меньше риск переобучения)\n",
    "\n",
    "b. Параметры леса\n",
    "    1. n_estimators - кол-во деревьев (чем больше тем лучше)\n",
    "    2. max_features - число признаков случайного подпространства\n",
    "    3. bootstrap - использовать ли бэггинг\n",
    "    4. n_jobs - кол-во потоков для одновременного построения деревьев (большая прибавка к скорости на многоядерных процах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'МИНИМАЛЬНОЕ ЧИСЛО ОБЪЕКТОВ В ЛИСТЕ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'минимальное число объектов в листе'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features=0.8, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=20, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf_rf = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_leaf=20, max_features=0.8, n_jobs=-1)\n",
    "\n",
    "clf_rf.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8396580318322792"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878866577765313"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Важность признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn - усредненное по всем деревьям в ансамбле кол-во сплитов по признаку, взвешенное на прирост информации (Information gain) и долю объектов в вершине, в которой производится этот сплит\n",
    "\n",
    "Это не единственный вариант, см здесь:\n",
    "\n",
    "https://medium.com/@ceshine/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3\n",
    "\n",
    "Важности признаков случайного леса лежат в артибуте **feature\\_importances\\_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverallQual             0.630280\n",
       "GrLivArea               0.116510\n",
       "GarageCars              0.050254\n",
       "TotalBsmtSF             0.034308\n",
       "BsmtFinSF1              0.032420\n",
       "ExterQual_TA            0.025381\n",
       "GarageArea              0.021035\n",
       "1stFlrSF                0.016338\n",
       "LotArea                 0.013064\n",
       "BsmtQual_Ex             0.009876\n",
       "YearBuilt               0.008766\n",
       "MasVnrArea              0.004340\n",
       "GarageType_Attchd       0.003999\n",
       "YearRemodAdd            0.002797\n",
       "2ndFlrSF                0.002566\n",
       "TotRmsAbvGrd            0.002334\n",
       "GarageYrBlt             0.002157\n",
       "FullBath                0.002068\n",
       "Fireplaces              0.001822\n",
       "LotShape_Reg            0.001691\n",
       "KitchenQual_Ex          0.001490\n",
       "ExterQual_Gd            0.001451\n",
       "KitchenQual_Gd          0.001383\n",
       "OpenPorchSF             0.001269\n",
       "BsmtQual_Gd             0.001190\n",
       "LotFrontage             0.001069\n",
       "MasVnrType_None         0.000921\n",
       "KitchenQual_TA          0.000915\n",
       "CentralAir_N            0.000881\n",
       "CentralAir_Y            0.000759\n",
       "                          ...   \n",
       "Exterior2nd_Stucco      0.000000\n",
       "Neighborhood_Sawyer     0.000000\n",
       "Neighborhood_NridgHt    0.000000\n",
       "PoolQC_Fa               0.000000\n",
       "Functional_Mod          0.000000\n",
       "ExterCond_TA            0.000000\n",
       "BsmtFinType2_ALQ        0.000000\n",
       "Neighborhood_Veenker    0.000000\n",
       "Condition1_RRAe         0.000000\n",
       "LandContour_Lvl         0.000000\n",
       "SaleType_Oth            0.000000\n",
       "Neighborhood_MeadowV    0.000000\n",
       "LandSlope_Sev           0.000000\n",
       "BsmtFinType2_Unf        0.000000\n",
       "Neighborhood_NWAmes     0.000000\n",
       "Neighborhood_ClearCr    0.000000\n",
       "BsmtFinType1_LwQ        0.000000\n",
       "MSZoning_FV             0.000000\n",
       "Neighborhood_BrkSide    0.000000\n",
       "Neighborhood_Gilbert    0.000000\n",
       "RoofMatl_Tar&Grv        0.000000\n",
       "PoolQC_Gd               0.000000\n",
       "Neighborhood_Mitchel    0.000000\n",
       "RoofStyle_Gable         0.000000\n",
       "Exterior1st_Plywood     0.000000\n",
       "MSZoning_RH             0.000000\n",
       "Exterior1st_Stucco      0.000000\n",
       "PavedDrive_N            0.000000\n",
       "Fence_GdWo              0.000000\n",
       "Exterior2nd_Wd Sdng     0.000000\n",
       "Length: 255, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.Series(clf_rf.feature_importances_, index=X_train.columns)\n",
    "imp.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Композиции моделей разных типов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная комбинация моделей разного типа\n",
    "\n",
    "Смешаем дерево и логистическую регрессию\n",
    "\n",
    "**Создаем признаки для лог регрессии**\n",
    "\n",
    "1. Заменяем пропуски на медианы\n",
    "2. Создаем индикаторы пропущенных значений\n",
    "3. Создаем дамми-переменные для категорий\n",
    "4. Нормируем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_median = d_train[num_feat].median()\n",
    "\n",
    "X_train_lin = pd.concat([d_train[num_feat].fillna(train_median),\n",
    "                     d_train[num_feat + cat_feat].isnull().astype(np.int8).add_suffix('_NaN'),\n",
    "                     dummy_train], axis=1)\n",
    "\n",
    "X_test_lin = pd.concat([d_test[num_feat].fillna(train_median),\n",
    "                     d_test[num_feat + cat_feat].isnull().astype(np.int8).add_suffix('_NaN'),\n",
    "                     dummy_test], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_lin[num_feat])\n",
    "\n",
    "X_train_lin[num_feat] = scaler.transform(X_train_lin[num_feat])\n",
    "X_test_lin[num_feat] = scaler.transform(X_test_lin[num_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "\n",
    "clf_lr.fit(X_train_lin, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05577299412915851"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.score(X_train_lin, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00684931506849315"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.score(X_test_lin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем строить линейную комбинацию вида\n",
    "\n",
    "$y = \\alpha y_1 + (1 - \\alpha) y_2$\n",
    "\n",
    "Параметр $\\alpha$ переберем по сетке от 0 до 1, оценивая качество на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin_test = clf_lr.predict_proba(X_test_lin)\n",
    "y_pred_rf_test = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (438,544) (438,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f8f8251f23f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malpha_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred_lin_test\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred_rf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maucs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maucs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (438,544) (438,) "
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "alpha_space = np.linspace(0, 1, 100)\n",
    "for alpha in alpha_space:\n",
    "    y_pred_weight = alpha * y_pred_lin_test + (1 - alpha) * y_pred_rf_test\n",
    "    aucs.append(calc_auc(y_test, y_pred_weight, prin=False))\n",
    "aucs = np.array(aucs)    \n",
    "\n",
    "max_ind = np.where(aucs == aucs.max())[0]\n",
    "alpha = alpha_space[max_ind]\n",
    "\n",
    "plt.plot(alpha_space, aucs)\n",
    "plt.plot(alpha_space[max_ind], aucs[max_ind], 'o', c='r')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('auc')\n",
    "\n",
    "#итоговое взвешенное предсказание\n",
    "y_pred_weight = alpha * y_pred_lin_test + (1 - alpha) * y_pred_rf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним 3 метода (приблизим график ROC кривой, чтобы увидеть разницу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Weighted:')\n",
    "# calc_auc(y_test, y_pred_weight, 'weighted')\n",
    "# print('Log regression:')\n",
    "# calc_auc(y_test, y_pred_lin_test, 'LR')\n",
    "# print('Random forest:')\n",
    "# calc_auc(y_test, y_pred_rf_test, 'RF')\n",
    "# plt.legend();\n",
    "# plt.xlim(0.2, 0.5)\n",
    "# plt.ylim(0.5, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стэкинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Средние значения таргета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новые признаки, на основе категориальных переменных. Каждому уникальному значению $V$ переменной $X_i$ сопоставим среднее значение таргета среди всех объектов, у которых переменная $X_i$ принимает значение $V$ \n",
    "\n",
    "Новый признак со средними значением таргета в категории можно считать за предсказание вер-ти класса 1 простого классификатора \"усреднения\"\n",
    "\n",
    "Опишем класс этого классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanClassifier():\n",
    "    def __init__(self, col):\n",
    "        self._col = col\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._y_mean = y.mean()\n",
    "        self._means = y.groupby(X[self._col].astype(str)).mean()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        new_feature = X[self._col].astype(str)\\\n",
    "            .map(self._means.to_dict())\\\n",
    "            .fillna(self._y_mean)\n",
    "        return np.stack([1-new_feature, new_feature], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания по фолдам кросс-валидации. **Главное не допустить утечки информации!**\n",
    "\n",
    "Опишем функцию для стекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_features(clf, X_train, y_train, X_test, stack_cv):\n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(y_test, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(stack_cv.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind])\n",
    "        meta_train[test_ind] = clf.predict_proba(X_train.iloc[test_ind])[:, 1]\n",
    "        meta_test += clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return meta_train, meta_test / stack_cv.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_meta_features2(clf, X_train, y_train, X_test, stack_cv):\n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(y_test, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(stack_cv.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind])\n",
    "        meta_train[test_ind] = clf.predict_proba(X_train.iloc[test_ind])[:, 1]\n",
    "        meta_test += clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return meta_train, meta_test / stack_cv.n_splits\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stack_cv = StratifiedKFold(n_splits=10, random_state=555)\n",
    "\n",
    "meta_train = []\n",
    "meta_test = []\n",
    "col_names = []\n",
    "\n",
    "print('mean features...')\n",
    "for c in cat_nunique.index.tolist():\n",
    "    clf = MeanClassifier(c)\n",
    "    \n",
    "    meta_tr, meta_te = get_meta_features2(clf, d_train, y_train, d_test, stack_cv)\n",
    "\n",
    "    meta_train.append(meta_tr)\n",
    "    meta_test.append(meta_te)\n",
    "    col_names.append('mean_pred_{}'.format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг нескольких моделей\n",
    "0. Средние значения\n",
    "1. Random Forest\n",
    "2. Log reg\n",
    "3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое качество дает линейный SVM\n",
    "\n",
    "для совместимости с общим кодом стекинга немного модифицируем класс SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def norm(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "class SVMWrapper(LinearSVC):\n",
    "    def predict_proba(self, X):\n",
    "        df = norm(self.decision_function(X))\n",
    "        return np.stack([1-df, df], axis=1)\n",
    "\n",
    "clf_svm = SVMWrapper(C=0.001)    \n",
    "clf_svm.fit(X_train_lin, y_train)\n",
    "\n",
    "y_pred_svm_test = clf_svm.predict_proba(X_test_lin)[:, 1]\n",
    "y_pred_svm_train = clf_svm.predict_proba(X_train_lin)[:, 1]\n",
    "\n",
    "# print('Train:')\n",
    "# calc_auc(y_train, y_pred_lin_train, 'train')\n",
    "# print('Test:')\n",
    "# calc_auc(y_test, y_pred_lin_test, 'test')\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим мета признаки для 3х моделей:\n",
    "* SVM\n",
    "* Logreg\n",
    "* Random Forest\n",
    "и средних значений по каждой категориальной переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MeanClassifier' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-32450b34110e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmeta_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmeta_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-3b9f4d102316>\u001b[0m in \u001b[0;36mget_meta_features\u001b[0;34m(clf, X_train, y_train, X_test, stack_cv)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmeta_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmeta_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MeanClassifier' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "stack_cv = StratifiedKFold(n_splits=10, random_state=555)\n",
    "\n",
    "meta_train = []\n",
    "meta_test = []\n",
    "col_names = []\n",
    "\n",
    "print('mean features...')\n",
    "for c in cat_nunique.index.tolist():\n",
    "    clf = MeanClassifier(c)\n",
    "    \n",
    "    meta_tr, meta_te = get_meta_features(clf, d_train, y_train, d_test, stack_cv)\n",
    "\n",
    "    meta_train.append(meta_tr)\n",
    "    meta_test.append(meta_te)\n",
    "    col_names.append('mean_pred_{}'.format(c))\n",
    "\n",
    "print('SVM features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_svm, X_train_lin, y_train, X_test_lin, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('svm_pred')\n",
    "\n",
    "print('LR features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_lr, X_train_lin, y_train, X_test_lin, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('lr_pred')\n",
    "\n",
    "print('RF features...')\n",
    "meta_tr, meta_te = get_meta_features(clf_rf, X_train, y_train, X_test, stack_cv)\n",
    "\n",
    "meta_train.append(meta_tr)\n",
    "meta_test.append(meta_te)\n",
    "col_names.append('rf_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_train = pd.DataFrame(np.stack(meta_train, axis=1), columns=col_names)\n",
    "X_meta_test = pd.DataFrame(np.stack(meta_test, axis=1), columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стэкинг мета-признаков с помощью LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем регуляризованную лог регрессию в качестве алгоритма второго уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr_meta = LogisticRegression(penalty='l2', C=1)\n",
    "\n",
    "clf_lr_meta.fit(X_meta_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-f0a51c866f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred_meta_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_lr_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_meta_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcalc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_meta_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d241f587dabe>\u001b[0m in \u001b[0;36mcalc_auc\u001b[0;34m(y, y_pred, plot_label, prin)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mauc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC AUC: {0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "y_pred_meta_test = clf_lr_meta.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "calc_auc(y_test, y_pred_meta_test, 'test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим на коэффициенты объединяющей линейной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим интерпретацию общей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 23392, placement implies 43",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-67e8a82d3d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_lr_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_meta_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'barh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    264\u001b[0m                                        raise_cast_failure=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   4400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m             block = make_block(block, placement=slice(0, len(axis)), ndim=1,\n\u001b[0;32m-> 4402\u001b[0;31m                                fastpath=True)\n\u001b[0m\u001b[1;32m   4403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2955\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   2956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2957\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m    118\u001b[0m             raise ValueError('Wrong number of items passed %d, placement '\n\u001b[1;32m    119\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[0;32m--> 120\u001b[0;31m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 23392, placement implies 43"
     ]
    }
   ],
   "source": [
    "pd.Series(clf_lr_meta.coef_.flatten(), index=X_meta_train.columns).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа\n",
    "\n",
    "#### Простая\n",
    "1. Теперь решаем задачу регрессии - предскажем цены на недвижимость. Использовать датасет https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data (train.csv)\n",
    "2. Данных немного, поэтому необходимо использовать 10-fold кросс-валидацию для оценки качества моделей\n",
    "3. Построить случайный лес, вывести важность признаков\n",
    "4. Обучить стекинг как минимум 3х моделей, использовать хотя бы 1 линейную модель и 1 нелинейную\n",
    "5. Для валидации модели 2-го уровня использовать отдельный hold-out датасет, как на занятии\n",
    "6. Показать, что использование ансамблей моделей действительно улучшает качество (стекинг vs другие модели сравнивать на hold-out)\n",
    "7. В качестве решения:\n",
    "    Jupyter notebook с кодом, комментариями и графиками\n",
    "\n",
    "#### Средняя\n",
    "0. Все то же, что и в части 1, плюс:\n",
    "1. Попробовать другие оценки важности переменных, например Boruta\n",
    "http://danielhomola.com/2015/05/08/borutapy-an-all-relevant-feature-selection-method/#comments\n",
    "3. Изучить extremely randomized trees (ExtraTreesRegressor в sklearn), сравнить с Random Forest\n",
    "4. Проводить настройку гиперпараметров для моделей первого уровня в стекинге (перебирать руками и смотреть на CV или по сетке: GridSearchCV, RandomizedSearchCV)\n",
    "5. Попробовать другие алгоритмы второго уровня\n",
    "6. Сделать сабмиты на kaggle (минимум 3: отдельные модели vs стекинг), сравнить качество на локальной валидации и на leaderboard\n",
    "7. В качестве решения:\n",
    "    * Jupyter notebook с кодом, комментариями и графиками\n",
    "    * сабмит на kaggle (ник на leaderboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "170px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
